
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Speaking Practice with WebRTC</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    video { width: 45%; margin: 10px; border: 1px solid #ccc; }
    .status { font-weight: bold; margin-top: 10px; }
    .correct { color: green; }
    .incorrect { color: red; }
    .questions { margin-top: 20px; }
  </style>
</head>
<body>
  <h2>Speaking Practice with WebRTC</h2>
  <div>
    <video id="localVideo" autoplay muted></video>
    <video id="remoteVideo" autoplay></video>
  </div>

  <div class="questions">
    <h3>Try saying one of these questions:</h3>
    <ul>
      <li>What are you doing now?</li>
      <li>Where are you now?</li>
      <li>What are you eating?</li>
      <li>Are you studying now?</li>
    </ul>
  </div>

  <button onclick="startRecognition()">üé§ Speak Now</button>
  <p id="recognizedText">You said: ...</p>
  <p id="feedback" class="status"></p>

  <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
  <script>
    const socket = io('http://localhost:3000');
    const localVideo = document.getElementById('localVideo');
    const remoteVideo = document.getElementById('remoteVideo');
    const peerConnection = new RTCPeerConnection();
    const recognizedText = document.getElementById('recognizedText');
    const feedback = document.getElementById('feedback');

    navigator.mediaDevices.getUserMedia({ video: true, audio: true })
      .then(stream => {
        localVideo.srcObject = stream;
        stream.getTracks().forEach(track => peerConnection.addTrack(track, stream));
      });

    peerConnection.ontrack = event => {
      remoteVideo.srcObject = event.streams[0];
    };

    peerConnection.onicecandidate = event => {
      if (event.candidate) {
        socket.emit('candidate', event.candidate);
      }
    };

    socket.on('offer', async offer => {
      await peerConnection.setRemoteDescription(new RTCSessionDescription(offer));
      const answer = await peerConnection.createAnswer();
      await peerConnection.setLocalDescription(answer);
      socket.emit('answer', answer);
    });

    socket.on('answer', async answer => {
      await peerConnection.setRemoteDescription(new RTCSessionDescription(answer));
    });

    socket.on('candidate', async candidate => {
      await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
    });

    async function createOffer() {
      const offer = await peerConnection.createOffer();
      await peerConnection.setLocalDescription(offer);
      socket.emit('offer', offer);
    }

    createOffer();

    function startRecognition() {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      recognition.lang = 'en-US';
      recognition.interimResults = false;
      recognition.maxAlternatives = 1;

      recognition.start();

      recognition.onresult = event => {
        const transcript = event.results[0][0].transcript.trim();
        recognizedText.textContent = 'You said: ' + transcript;

        const validQuestions = [
          "what are you doing now",
          "where are you now",
          "what are you eating",
          "are you studying now"
        ];

        const normalized = transcript.toLowerCase();
        if (validQuestions.includes(normalized)) {
          feedback.textContent = "‚úÖ Correct!";
          feedback.className = "status correct";
          speakFeedback("Good job!");
        } else {
          feedback.textContent = "‚ùå Please try again.";
          feedback.className = "status incorrect";
        }
      };

      recognition.onerror = event => {
        feedback.textContent = "‚ùå Recognition error: " + event.error;
        feedback.className = "status incorrect";
      };
    }

    function speakFeedback(text) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'en-US';
      speechSynthesis.speak(utterance);
    }
  </script>
</body>
</html>
